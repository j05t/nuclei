{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nuclei.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [
        "G9d8MOANX5cR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K1DrrYYmaJGc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initial Setup\n",
        "Download and extract dataset. Upload previously saved model weights. Execute only once."
      ]
    },
    {
      "metadata": {
        "id": "pZaVlQUPb2Hg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# check if data directory is present\n",
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2wAoIU4dclfa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# upload previously saved model weights \n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# save as file into current working directory\n",
        "with open(\"model-1.h5\", \"wb\") as f:\n",
        "  f.write(uploaded[\"model-1.h5\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vfD-Zo1laTYX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wMCEPZPmQYTQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# download data files and labels\n",
        "# drive.CreateFile({'id': '1kkOgZp7aul6v-9K7H11uxOHM7f21VUPi'}).GetContentFile('stage1_sample_submission.csv.zip')\n",
        "drive.CreateFile({'id': '1KvOWg2QolRvaiAmFLR5nJ3n7sP5-i_SL'}).GetContentFile('stage1_test.zip')\n",
        "drive.CreateFile({'id': '1kkOgZp7aul6v-9K7H11uxOHM7f21VUPi'}).GetContentFile('stage1_train_labels.csv.zip')\n",
        "drive.CreateFile({'id': '1wnZMeMNn-tZrSdFGCS4QFKN8dm3Tf5nS'}).GetContentFile('stage1_train.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqzw3orDX3__",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# create data directories\n",
        "!mkdir -p data/test\n",
        "!mkdir -p data/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95oPOBfpY47a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# unzip files\n",
        "!unzip -qq -o stage1_test.zip -d data/test\n",
        "!unzip -qq -o stage1_train.zip -d data/train\n",
        "!unzip -qq -o stage1_train_labels.csv.zip -d data\n",
        "# !unzip -qq -o stage1_sample_submission.csv.zip -d data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FKmCKtQqb9Vw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define model and visualize data"
      ]
    },
    {
      "metadata": {
        "id": "7TaJPHGIFw_a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==1.4.1 keras tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QyYeVhUixsgA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adapted U-net implementation from Kjetil Åmdal-Sævik: https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277"
      ]
    },
    {
      "metadata": {
        "id": "nLNpKMANUIBx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# show available devices\n",
        "# from tensorflow.python.client import device_lib\n",
        "# device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YxAIbmzUfXa8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "from keras import backend as K\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set some parameters\n",
        "IMG_WIDTH = 256  # width/height in original script was 128\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 3\n",
        "TRAIN_PATH = 'data/train/'\n",
        "TEST_PATH = 'data/test/'\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "seed = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7KGPK2JZw6fg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Get train and test IDs\n",
        "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids = next(os.walk(TEST_PATH))[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "alKKH84k63iF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import the images and associated masks and rescale to 256x256."
      ]
    },
    {
      "metadata": {
        "id": "kaqutkGLx5fP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Get and resize train images and masks\n",
        "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = TRAIN_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_train[n] = img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "        mask_ = imread(path + '/masks/' + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)\n",
        "    Y_train[n] = mask\n",
        "\n",
        "# Get and resize test images\n",
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "sizes_test = []\n",
        "print('Getting and resizing test images ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    path = TEST_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    sizes_test.append([img.shape[0], img.shape[1]])\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_test[n] = img\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bBPl28g5x9GO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Display random sample data\n",
        "ix = random.randint(0, len(train_ids))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dkDIsYeb7OEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Keras metrics\n",
        "Try different metrics:\n",
        "* Intersection over union (IoU, or Jaccard index) https://en.wikipedia.org/wiki/Jaccard_index\n",
        "* Dice coefficient https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient"
      ]
    },
    {
      "metadata": {
        "id": "TeVTPYkC7Q3F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define IoU metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lh4wvKhRgOHg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# we are not using dice coeffienct metric\n",
        "\n",
        "# dice coefficient implementation from\n",
        "# https://github.com/jocicmarko/ultrasound-nerve-segmentation\n",
        "\n",
        "# dice coefficient metric\n",
        "smooth = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zyc2gOsl7aHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define neural network\n",
        "U-Net model, loosely based on U-Net: Convolutional Networks for Biomedical Image Segmentation https://arxiv.org/pdf/1505.04597.pdf and very similar to https://github.com/jocicmarko/ultrasound-nerve-segmentation"
      ]
    },
    {
      "metadata": {
        "id": "X2FNp0Kn7cvY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Build U-Net model\n",
        "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
        "c1 = BatchNormalization(axis=1) (c1)\n",
        "c1 = Dropout(0.1) (c1)\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "c1 = BatchNormalization(axis=1) (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "c2 = BatchNormalization(axis=1) (c2)\n",
        "c2 = Dropout(0.1) (c2)\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "c2 = BatchNormalization(axis=1) (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "c3 = BatchNormalization(axis=1) (c3)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "c3 = BatchNormalization(axis=1) (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "c4 = BatchNormalization(axis=1) (c4)\n",
        "c4 = Dropout(0.2) (c4)\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "c4 = BatchNormalization(axis=1) (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "c5 = BatchNormalization(axis=1) (c5)\n",
        "c5 = Dropout(0.3) (c5)\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "c5 = BatchNormalization(axis=1) (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "c6 = BatchNormalization(axis=1) (c6)\n",
        "c6 = Dropout(0.2) (c6)\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "c6 = BatchNormalization(axis=1) (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "c7 = BatchNormalization(axis=1) (c7)\n",
        "c7 = Dropout(0.2) (c7)\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "c8 = BatchNormalization(axis=1) (c8)\n",
        "c8 = Dropout(0.1) (c8)\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "c9 = BatchNormalization(axis=1) (c9)\n",
        "c9 = Dropout(0.1) (c9)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2GhIp_ytUMR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OabKhiF7M-0L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data augmentation\n",
        "Imagedatagenerator documentation at https://keras.io/preprocessing/image/\n",
        "* keras augmentation implementation from https://www.kaggle.com/c0conuts/unet-imagedatagenerator-lb-0-336\n",
        "* elastic transforms implementation from https://www.kaggle.com/ori226/data-augmentation-with-elastic-deformations\n"
      ]
    },
    {
      "metadata": {
        "id": "f05s7dcaTGp7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Elastic transform"
      ]
    },
    {
      "metadata": {
        "id": "1-ujHNk5eHn4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# install and import opencv\n",
        "# !apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yd4MfZuLUkEt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Function to distort image\n",
        "# from scipy.ndimage.interpolation import map_coordinates\n",
        "# from scipy.ndimage.filters import gaussian_filter\n",
        "\n",
        "# # Function to distort image\n",
        "# def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n",
        "#     \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
        "#     .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
        "#          Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
        "#          Proc. of the International Conference on Document Analysis and\n",
        "#          Recognition, 2003.\n",
        "\n",
        "#      Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
        "#     \"\"\"\n",
        "#     if random_state is None:\n",
        "#         random_state = np.random.RandomState(None)\n",
        "\n",
        "#     shape = image.shape\n",
        "#     shape_size = shape[:2]\n",
        "    \n",
        "#     # Random affine\n",
        "#     center_square = np.float32(shape_size) // 2\n",
        "#     square_size = min(shape_size) // 3\n",
        "#     pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
        "#     pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
        "#     M = cv2.getAffineTransform(pts1, pts2)\n",
        "#     image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "#     dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "#     dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "#     dz = np.zeros_like(dx)\n",
        "\n",
        "#     x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
        "#     indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "#     return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_5xB0x8U5hu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize elastic distortions."
      ]
    },
    {
      "metadata": {
        "id": "xYGf0jTvrLtx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load images\n",
        "#im = x.next()[0].astype(np.uint8)\n",
        "#im_mask = y.next()[0].astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-TrFAxbiskQ2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE=48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CklzWBptm6sW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# # Define function to draw a grid\n",
        "# def draw_grid(im, grid_size):\n",
        "#     # Draw grid lines\n",
        "#     for i in range(0, im.shape[1], grid_size):\n",
        "#         cv2.line(im, (i, 0), (i, im.shape[0]), color=(255,))\n",
        "# #     for j in range(0, im.shape[0], grid_size):\n",
        "#         cv2.line(im, (0, j), (im.shape[1], j), color=(255,))\n",
        "\n",
        "# # Load images\n",
        "# im = cv2.imread(\"../input/train/10_1.tif\", -1)\n",
        "# # im_mask = cv2.imread(\"../input/train/10_1_mask.tif\", -1)\n",
        "\n",
        "# # Draw grid lines\n",
        "# draw_grid(im, 50)\n",
        "# draw_grid(im_mask, 50)\n",
        "\n",
        "# # Merge images into separete channels (shape will be (cols, rols, 2))\n",
        "# im_merge = np.concatenate((im[...,None], im_mask[...,None]), axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkvRPhHY4MXN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# # First sample...\n",
        "\n",
        "# %matplotlib inline\n",
        "\n",
        "# # Apply transformation on image\n",
        "# im_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 2, im_merge.shape[1] * 0.08, im_merge.shape[1] * 0.08)\n",
        "\n",
        "# # Split image and mask\n",
        "# im_t = im_merge_t[...,0]\n",
        "# im_mask_t = im_merge_t[...,1]\n",
        "\n",
        "# # Display result\n",
        "# plt.figure(figsize = (16,14))\n",
        "# plt.imshow(np.c_[np.r_[im, im_mask], np.r_[im_t, im_mask_t]], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mYdJlqr4M4q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Second sample (heavyer transform)...\n",
        "\n",
        "# %matplotlib inline\n",
        "\n",
        "# # Apply transformation on image\n",
        "# im_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 3, im_merge.shape[1] * 0.07, im_merge.shape[1] * 0.09)\n",
        "\n",
        "# # Split image and mask\n",
        "# im_t = im_merge_t[...,0]\n",
        "# im_mask_t = im_merge_t[...,1]\n",
        "\n",
        "# # Display result\n",
        "# plt.figure(figsize = (16,14))\n",
        "# plt.imshow(np.c_[np.r_[im, im_mask], np.r_[im_t, im_mask_t]], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrKX0ddNnj04",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Imagedatagenerator"
      ]
    },
    {
      "metadata": {
        "id": "tAXrxTjeWCUv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SisTVbY5NCQA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "# Creating the training Image and Mask generator\n",
        "image_datagen = image.ImageDataGenerator(\n",
        "                                         shear_range=0.5, rotation_range=50, \n",
        "                                         zoom_range=0.2, width_shift_range=0.2, \n",
        "                                         height_shift_range=0.2, fill_mode='reflect')\n",
        "mask_datagen = image.ImageDataGenerator(\n",
        "                                        shear_range=0.5, rotation_range=50, \n",
        "                                        zoom_range=0.2, width_shift_range=0.2, \n",
        "                                        height_shift_range=0.2, fill_mode='reflect')\n",
        "\n",
        "# Keep the same seed for image and mask generators so they fit together\n",
        "image_datagen.fit(X_train[:int(X_train.shape[0]*0.9)], augment=True, seed=seed)\n",
        "mask_datagen.fit(Y_train[:int(Y_train.shape[0]*0.9)], augment=True, seed=seed)\n",
        "\n",
        "x=image_datagen.flow(X_train[:int(X_train.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
        "y=mask_datagen.flow(Y_train[:int(Y_train.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
        "\n",
        "\n",
        "# Creating the validation Image and Mask generator\n",
        "image_datagen_val = image.ImageDataGenerator()\n",
        "mask_datagen_val = image.ImageDataGenerator()\n",
        "\n",
        "image_datagen_val.fit(X_train[int(X_train.shape[0]*0.9):], augment=True, seed=seed)\n",
        "mask_datagen_val.fit(Y_train[int(Y_train.shape[0]*0.9):], augment=True, seed=seed)\n",
        "\n",
        "x_val=image_datagen_val.flow(X_train[int(X_train.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)\n",
        "y_val=mask_datagen_val.flow(Y_train[int(Y_train.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ijAlZQPYL6d6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#creating a training and validation generator that generate masks and images\n",
        "train_generator = zip(x, y)\n",
        "val_generator = zip(x_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zKdMUf0NfdN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Check if images/masks fit\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "imshow(x.next()[0].astype(np.uint8))\n",
        "plt.show()\n",
        "imshow(np.squeeze(y.next()[0].astype(np.uint8)))\n",
        "plt.show()\n",
        "imshow(x_val.next()[0].astype(np.uint8))\n",
        "plt.show()\n",
        "imshow(np.squeeze(y_val.next()[0].astype(np.uint8)))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lwi-Uc_imhNy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model\n",
        "Train model with early stopping if loss does not improve for a number of epochs. Additional callbacks to record the loss history and to save best model weights."
      ]
    },
    {
      "metadata": {
        "id": "rV3_8osqfRJc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# callback to record loss history\n",
        "# https://keras.io/callbacks/#example-recording-loss-history\n",
        "class LossHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DddcEJdumIJ6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "history = LossHistory()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ep7DaSgQVug7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# upload model weights \n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "# save as file into current working directory\n",
        "#with open(\"model-1.h5\", \"wb\") as f:\n",
        "#  f.write(uploaded[\"model-1.h5\"])\n",
        "  \n",
        "# verify model weights have been uploaded into current working directory\n",
        "#!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-HMswPoBxIp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# load saved model weigths\n",
        "model = load_model('model-1.h5', custom_objects={'mean_iou': mean_iou})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNVRixBG7i9v",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# fit model using realtime data augmentation\n",
        "earlystopper = EarlyStopping(patience=15, verbose=1)\n",
        "checkpointer = ModelCheckpoint('model-1.h5', verbose=1, save_best_only=True)\n",
        "results = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=10, steps_per_epoch=250,\n",
        "                              epochs=100, callbacks=[earlystopper, checkpointer, history])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wi1AViJC4qll",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# download model weights\n",
        "from google.colab import files\n",
        "files.download('model-1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2CVy5LfIf3r9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot loss history\n",
        "https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
      ]
    },
    {
      "metadata": {
        "id": "P6o0PGhtf2Gc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.losses)\n",
        "plt.plot(history.val_losses)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qdkMgV1lXgty",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict on train, val and test\n",
        "Let's make predictions both on the test set, the val set and the train set (as a sanity check). Remember to load the best saved model if you've used early stopping and checkpointing."
      ]
    },
    {
      "metadata": {
        "id": "UR3LW-XZXsow",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Predict on train, val and test\n",
        "model = load_model('model-1.h5', custom_objects={'mean_iou': mean_iou})\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "# Create list of upsampled test masks\n",
        "preds_test_upsampled = []\n",
        "for i in range(len(preds_test)):\n",
        "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
        "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
        "                                       mode='constant', preserve_range=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_jGJ5cfXu76",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Perform a sanity check on some random training samples\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_train_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C9utwotvXwtZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Perform a sanity check on some random validation samples\n",
        "ix = random.randint(0, len(preds_val_t))\n",
        "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_val_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PGVJJtQrl7k0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# show random sample for test dataset and predicted mask \n",
        "ix = random.randint(0, len(preds_test_t))\n",
        "imshow(np.squeeze(X_test[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_test[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_test_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G9d8MOANX5cR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Encode and submit results to kaggle\n",
        "Code for run length encoding from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python"
      ]
    },
    {
      "metadata": {
        "id": "LRv7f90rX-zH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Run-length encoding\n",
        "def rle_encoding(x):\n",
        "    dots = np.where(x.T.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "def prob_to_rles(x, cutoff=0.5):\n",
        "    lab_img = label(x > cutoff)\n",
        "    for i in range(1, lab_img.max() + 1):\n",
        "        yield rle_encoding(lab_img == i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXYifdYyYDGn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage ...\n"
      ]
    },
    {
      "metadata": {
        "id": "RHweOCF9YBhv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "new_test_ids = []\n",
        "rles = []\n",
        "for n, id_ in enumerate(test_ids):\n",
        "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
        "    rles.extend(rle)\n",
        "    new_test_ids.extend([id_] * len(rle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4OaUBNNFYH92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create submission."
      ]
    },
    {
      "metadata": {
        "id": "kugzusOlYESm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create submission DataFrame\n",
        "sub = pd.DataFrame()\n",
        "sub['ImageId'] = new_test_ids\n",
        "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
        "sub.to_csv('results.csv', index=False) # save csv locally"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RnzpkqNWaTUS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# create results.csv on the client side\n",
        "# https://stackoverflow.com/questions/31893930/download-csv-from-an-ipython-notebook\n",
        "from IPython.display import Javascript\n",
        "js_download = \"\"\"\n",
        "var csv = '%s';\n",
        "\n",
        "var filename = 'results.csv';\n",
        "var blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' });\n",
        "if (navigator.msSaveBlob) { // IE 10+\n",
        "    navigator.msSaveBlob(blob, filename);\n",
        "} else {\n",
        "    var link = document.createElement(\"a\");\n",
        "    if (link.download !== undefined) { // feature detection\n",
        "        // Browsers that support HTML5 download attribute\n",
        "        var url = URL.createObjectURL(blob);\n",
        "        link.setAttribute(\"href\", url);\n",
        "        link.setAttribute(\"download\", filename);\n",
        "        link.style.visibility = 'hidden';\n",
        "        document.body.appendChild(link);\n",
        "        link.click();\n",
        "        document.body.removeChild(link);\n",
        "    }\n",
        "}\n",
        "\"\"\" % sub.to_csv(index=False).replace('\\n','\\\\n').replace(\"'\",\"\\'\")\n",
        "\n",
        "Javascript(js_download)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J1R6COmV0Vjf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}